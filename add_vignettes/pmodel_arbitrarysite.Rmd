---
title: "P-model at arbitrary sites"
author: "Beni Stocker"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{P-model at arbitrary sites}
  %\VignetteEngine{knitr::rmarkdown}
  %\usepackage[utf8]{inputenc}
---

## Aim

This vignette demonstrates the use of {rsofun} for an ensemble of arbitrary points on the globe, given their longitude and latitude coordinates. Model forcing is constructed by reading data from global climate data. This is in contrast to using measured time series of climatic variables obtained from a site network (as described in [this article](./vignettes/pmodel_fluxnet.Rmd).

The R package {ingestr} is used for collecting point-level forcing time series. Install it directly from GitHub (see code chunk at the top of this article).

In this vignette, we use the paths corresponding to the GECO data archive (more information [here](https://github.com/geco-bern/data_management)). Note that this code reads files from their local paths. These files are not contained by the *rsofundemo* repository.

Finally, we format the data to run the [rsofun](https://geco-bern.github.io/rsofun/) P-model implementation.

## Libraries

First, load required libraries available on CRAN.
```{r message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(here)
library(visdat)
```

Then, install and load required libraries that are not on CRAN. Instead, obtain them directly from GitHub.
```{r}
if(!require(remotes)){install.packages(remotes)}
remotes::install_github("geco-bern/rsofun")
remotes::install_github("geco-bern/ingestr")
library(rsofun)
library(ingestr)
```


## Collect data

### Site meta information

The following site and simulation meta information are required for the forcing data generation. They need to be specified as columns in a data frame with sites (in column `sitename`) along rows:

- `lon`: longitude, degrees east
- `lat`: latitude, degrees north
- `year_start`: start year of the simulation
- `year_end`: end year of the simulation
- `elv`: elevation (m a.s.l.)
- `whc`: root zone water storage capacity (m)

This data frame needs to be specified by the user.
```{r}
siteinfo <- tibble(
  sitename = c("site1", "site2", "site3"), # AU-How, CH-Dav, US-Ha1
  lon = c(131.149994, 9.855910, -72.171500),
  lat = c(-12.495200, 46.815330, 42.53780)
) |> 
  mutate(
    year_start = 2018,
    year_end = 2018
  )
```

Site elevation and the root zone water storage capacity can be read from global maps.

#### Elevation {-}

```{r warning=FALSE, eval = FALSE}
df_elv <- ingest(
  siteinfo,
  source = "etopo1",
  dir = "~/data/etopo/"  # adjust this with your local path
) |> 
  unnest(data)

siteinfo <- siteinfo |> 
  left_join(
    df_elv,
    by = "sitename"
  )
```


#### Root zone water storage capacity {-}

```{r warning=FALSE, eval = FALSE}
df_whc <- ingest(
  siteinfo,
  source = "stocker23",
  dir = "~/data/mct_data/"  # adjust this with your local path
) |> 
  unnest(data)

siteinfo <- siteinfo |> 
  left_join(
    df_whc,
    by = "sitename"
  )
```

### Meteorological forcing

The following meteorological variables are obtained for the P-model forcing
from the [WATCH-WFDEI](https://rda.ucar.edu/datasets/ds314.2/) data for the following variables in {rsofun} standard naming:

- `temp`: Daily temperature
- `prec`: Daily precipitation
- `ppfd`: Photosynthetic photon flux density
- `vpd`: Vapor pressure deficit
- `patm`: Atmospheric pressure

WATCH-WFDEI data is provided at a spatial resolution of 0.5 degrees. To minimise errors related to small-scale climatic gradients related to topography, we use a simple downscaling based on the WorldClim high resolution (1/120 degrees globally) monthly climatology. The downscaling is based on removing the bias by month (for temperature, PPFD, atmospheric pressure) or re-scaling to avoid bias (for precipitation and VPD). This is implemented in `ingestr::ingest()`.

Loading this data can take a while, up to hours if you need several years of data and for many sites.

```{r, eval=FALSE, message=FALSE, warning=FALSE}
# local paths on GECO server
path_watch <- "/data/archive/wfdei_weedon_2014/data"
path_worldclim <- "/data/archive/worldclim_fick_2017/data"

# local path on Beni Laptop
path_watch <- "~/data/watch_wfdei"

df_watch <- ingest(
  siteinfo = siteinfo,
  source = "watch_wfdei",
  getvars = c("temp", "prec", "ppfd", "vpd", "patm"),
  dir = path_watch
  # settings = list(
  #   correct_bias = "worldclim",
  #   dir_bias = path_worldclim
  # )
)
```

### Cloud cover from CRU

Now, let's complete the forcing with cloud cover `ccov` values from 
[CRU](https://crudata.uea.ac.uk/cru/data/hrg/) data. 

```{r, eval=FALSE}
# Get CRU data
path_cru <- "/data/archive/cru_NA_2021/data/"

df_cru <- ingestr::ingest(
  siteinfo = siteinfo,
  source = "cru",
  getvars = c("ccov"),
  dir = path_cru,
  settings = list(
    correct_bias = NULL   # 0.5 deg resolution
  )
)
```

### Merge meteorological drivers

Let's put together the previous data, into a single data.frame:
```{r, eval=FALSE}
df_meteo <- df_watch |>
  tidyr::unnest(data) |>
  left_join(
    df_cru |>
      tidyr::unnest(data),
    by = c("sitename", "date")
  ) |>
  dplyr::ungroup() |>                         # keep unnested
  dplyr::mutate(
    tmin = temp,
    tmax = temp
    )

head(df_meteo)
```

### Get CO2 data

The following chunk downloads the CO2 yearly average data from the Mauna Loa 
observatory and appends it to the meteorological drivers from above.
```{r, eval=FALSE}
# Download CO2 data
df_co2 <- read.csv(
  url("https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_annmean_mlo.csv"),
  skip = 59) |>
  dplyr::select(year, mean) |>
  dplyr::rename(co2 = mean)

# Merge with meteo drivers
df_meteo <- df_meteo |>
  dplyr::mutate(year = lubridate::year(date)) |>
  dplyr::left_join(df_co2, by = "year")            # keep unnested
```

### Append fAPAR

Specify settings for downloadig point-scale MODIS data ('subsets').
```{r warning=FALSE, eval = FALSE}
settings_modis <- get_settings_modis(
  bundle            = "modis_fpar",
  data_path         = "~/data/modis_subsets/",
  method_interpol   = "loess",
  keep              = TRUE,
  overwrite_raw     = FALSE,
  overwrite_interpol= FALSE
  )
```

This can now be used to download the data to the directory specified by argument `data_path` of function `get_settings_modis()`.

```{r warning=FALSE, eval = FALSE}
df_modis_fpar <- ingest(
  siteinfo, 
  source = "modis",
  settings = settings_modis, 
  parallel = FALSE
  )
```

## Put all data together into rsofun object

Up to here, we have merged all of the forcing data into `df_meteo`. Let's
put it in a nested format, such that there is a single data.frame per site:
```{r, eval=FALSE}
# Nest forcing
df_meteo <- df_meteo |>
  dplyr::group_by(sitename) |>
  tidyr::nest() |>
  dplyr::rename(forcing = data) |>
  dplyr::ungroup()

# Add site information
df_siteinfo <- siteinfo |>
  dplyr::group_by(sitename) |>
  tidyr::nest() |>
  dplyr::rename(site_info = data) |>
  dplyr::ungroup()
```

